apiVersion: v1
kind: ConfigMap
metadata:
  name: logging-cfg
  namespace: ns-logging
data:
  elasticsearch.yml: |
    cluster.name: ${cluster_name}
    #network.host: 0.0.0.0
    http.host: 0.0.0.0
    transport.host: 127.0.0.1
    # minimum_master_nodes need to be explicitly set when bound on a public IP
    # set to 1 to allow single node clusters
    # Details: https://github.com/elastic/elasticsearch/pull/17288
    discovery.zen.minimum_master_nodes: 1

    bootstrap.memory_lock: ${bootstrap_memory_lock}
    xpack.security.enabled: false
    xpack.watcher.enabled: false
    xpack.graph.enabled: false
    xpack.monitoring.enabled: false
  logstash.yml: |
    ## Default Logstash configuration from logstash-docker.
    ## from https://github.com/elastic/logstash-docker/blob/master/build/logstash/config/logstash.yml
    #
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline

    ## Disable X-Pack
    ## see https://www.elastic.co/guide/en/x-pack/current/xpack-settings.html
    xpack.monitoring.enabled: false
  logstash.conf: |
    # all input will come from filebeat, no local logs
    input {
      beats {
        port => 5044
      }
    }

    ## some more advanced filtering and tagging of incoming kubernetes logs is done in logstash
    filter {
      if [type] == "kube-logs" {
        mutate {
          rename => ["log", "message"]
          add_tag => [ "cluster-name", "aec" ]
        }

        date {
          match => ["time", "ISO8601"]
          remove_field => ["time"]
        }

        # all standard container logs files match a common pattern
        grok {
            match => { "source" => "/var/log/containers/%{DATA:pod_name}_%{DATA:namespace}_%{GREEDYDATA:container_name}-%{DATA:container_id}.log" }
            remove_field => ["source"]
        }

        # system services have a simpler log filename format that does not include namespace, pod names, or container ids
        grok {
            match => { "source" => "/var/log/hostlogs/%{DATA:container_name}.log" }
            add_field => { "namespace" => "kube-system" }
            remove_field => ["source"]
        }
      }
    }

    output {
        elasticsearch {
            hosts => [ "elasticsearch-service:9200" ]
        }
    }
  filebeat1.yml: |
    filebeat.registry_file: /var/tmp/filebeat/filebeat_registry # store the registry on the host filesystem so it doesn't get lost when pods are stopped
    filebeat.prospectors:
    # process all docker container logs, which are stored as json
    - input_type: log
      symlinks: true
      json.message_key: log
      json.keys_under_root: true
      json.add_error_key: true
      multiline.pattern: '^\s'
      multiline.match: after
      fields:
          host: ${FILEBEAT_HOST:${HOSTNAME}}
          type: kube-logs
      fields_under_root: true
      paths:
        - /var/log/containers/*.log
    # process system logs, such as kube-apiserver, kube-controller-manager, etc
    - input_type: log
      fields:
          host: ${FILEBEAT_HOST:${HOSTNAME}}
          type: kube-logs
      fields_under_root: true
      paths:
        - /var/log/hostlogs/kube*.log
    - input_type: log
      fields:
          host: ${FILEBEAT_HOST:${HOSTNAME}}
          type: kube-logs
      fields_under_root: true
      paths:
        - /var/lib/docker/containers/*/*.log
      json:
        keys_under_root: true
        message_key: log
      tags:
        - "json"
        - "docker"
    output.logstash:
      hosts: ["logstash-service:5044"]
  kibana.yml: |
    ## Default Kibana configuration from kibana-docker.
    ## from https://github.com/elastic/kibana-docker/blob/master/build/kibana/config/kibana.yml
    #
    server.name: kibana
    server.host: "0"
    elasticsearch.url: http://elasticsearch-service:9200

    ## Disable X-Pack
    ## see https://www.elastic.co/guide/en/x-pack/current/xpack-settings.html
    ##     https://www.elastic.co/guide/en/x-pack/current/installing-xpack.html#xpack-enabling
    #
    xpack.security.enabled: false
    xpack.monitoring.enabled: false
    xpack.ml.enabled: false
    xpack.graph.enabled: false
    xpack.reporting.enabled: false
  filebeat2.yml: |
    filebeat.prospectors:
    - input_type: log
    tags:
    - docker
    paths:
    - /var/lib/docker/containers/*/*.log
    json:
      keys_under_root: true
      add_error_key: true
      message_key: log
    multiline:
      pattern: '^[[:space:]]+|^Caused by:'
      negate: false
      match: after

    output.logstash:
      hosts: ["logstash-service:5000"]

    # Available log levels are: critical, error, warning, info, debug
    logging.level: info
  log4j2.properties: |
    status = error
    appender.console.type = Console
    appender.console.name = console
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] %marker%m%n
    rootLogger.level = info
    rootLogger.appenderRef.console.ref = console
  filebeat.yml: |
    filebeat.registry_file: /var/log/containers/filebeat_registry

    filebeat.prospectors:
    - input_type: log
      paths:
        - "/var/lib/docker/containers/*/*-json.log"
      #exclude_files: ['filebeat.*log','kube.*log']
      #symlinks: true
      #json.message_key: log
      #json.keys_under_root: true
      #json.add_error_key: true
      #multiline.pattern: '^\s'
      #multiline.match: after
      document_type: kube-logs

    output.logstash:
      hosts: ["logstash-service:5044"]
      timeout: 15
    # Available log levels are: critical, error, warning, info, debug
    logging.level: info
