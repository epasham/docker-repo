# my global config

global:

  scrape_interval:     10s # By default, scrape targets every 15 seconds.

  evaluation_interval: 10s # By default, scrape targets every 15 seconds.

  # scrape_timeout is set to the global default (10s).



  # Attach these labels to any time series or alerts when communicating with

  # external systems (federation, remote storage, Alertmanager).

  external_labels:

      monitor: 'ek-swarm'

# A scrape configuration containing exactly one endpoint to scrape:

# Here it's Prometheus itself.

scrape_configs:

  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.

  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'

    # scheme defaults to 'http'.

    static_configs:

         - targets: ['localhost:9090']



  - job_name: 'node'

    dns_sd_configs:

      - names: ['tasks.node']

        type: 'A'

        port: 9100



  - job_name: 'cadvisor'

    dns_sd_configs:

      - names: ['tasks.cadvisor']

        type: 'A'

        port: 8080
